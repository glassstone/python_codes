{
 "metadata": {
  "name": "",
  "signature": "sha256:b11988292c7aeaad81b721129aca65d83f403809716f0526ed213fdef876ef0d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def __init__():\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_modis(geofile,datfile):\n",
      "    \"\"\"\n",
      "    Name:\n",
      "\n",
      "        load_modis\n",
      "    \n",
      "    Purpose:\n",
      "\n",
      "        to compile functions required to load Modis files\n",
      "        from within another script\n",
      "    \n",
      "    Calling Sequence:\n",
      "\n",
      "        modis,modis_dict = load_modis(geofile,datfile) \n",
      "    \n",
      "    Input: \n",
      "  \n",
      "        geofile name\n",
      "        datfile name (hdf files)\n",
      "    \n",
      "    Output:\n",
      "\n",
      "        modis dictionary with tau, ref, etau, eref, phase, qa\n",
      "        modis_dicts : metadate for each of the variables\n",
      "    \n",
      "    Keywords: \n",
      "\n",
      "        none\n",
      "    \n",
      "    Dependencies:\n",
      "\n",
      "        gdal\n",
      "        numpy\n",
      "        gc: for clearing the garbage\n",
      "    \n",
      "    Required files:\n",
      "   \n",
      "        geo and dat files\n",
      "    \n",
      "    Example:\n",
      "\n",
      "        ...\n",
      "        \n",
      "    Modification History:\n",
      "    \n",
      "        Written (v1.0): Samuel LeBlanc, 2014-12-08, NASA Ames\n",
      "        \n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from osgeo import gdal\n",
      "    from Sp_parameters import startprogress, progress, endprogress\n",
      "    modis_values = (#('cloud_top',57),\n",
      "                    ('phase',53),\n",
      "          #          ('cloud_top_temp',58),\n",
      "                    ('ref',66),\n",
      "                    ('tau',72),\n",
      "           #         ('cwp',82),\n",
      "                    ('eref',90),\n",
      "                    ('etau',93),\n",
      "            #        ('ecwp',96),\n",
      "                    ('multi_layer',105),\n",
      "                    ('qa',123),\n",
      "             #       ('cloud_mask',110)\n",
      "                    )\n",
      "    geosds = gdal.Open(geofile)\n",
      "    datsds = gdal.Open(datfile)\n",
      "    geosub = geosds.GetSubDatasets()\n",
      "    datsub = datsds.GetSubDatasets()\n",
      "    print 'Outputting the Geo subdatasets:'\n",
      "    for i in range(len(geosub)):\n",
      "        print str(i)+': '+geosub[i][1]\n",
      "    print 'Outputting the Data subdatasets:'\n",
      "    for i in range(len(datsub)):\n",
      "        if any(i in val for val in modis_values):\n",
      "            print '\\x1b[1;36m%i: %s\\x1b[0m' %(i,datsub[i][1])\n",
      "        else:\n",
      "            print str(i)+': '+datsub[i][1]\n",
      "    latsds = gdal.Open(geosub[12][0],gdal.GA_ReadOnly)\n",
      "    lonsds = gdal.Open(geosub[13][0],gdal.GA_ReadOnly)\n",
      "    szasds = gdal.Open(geosub[21][0],gdal.GA_ReadOnly)\n",
      "    modis = dict()\n",
      "    modis['lat'] = latsds.ReadAsArray()\n",
      "    modis['lon'] = lonsds.ReadAsArray()\n",
      "    modis['sza'] = szasds.ReadAsArray()\n",
      "    print modis['lon'].shape\n",
      "    meta = datsds.GetMetadata() \n",
      "    import gc; gc.collect()\n",
      "    modis_dicts = dict()\n",
      "    startprogress('Running through modis values')\n",
      "    for i,j in modis_values:\n",
      "        sds = gdal.Open(datsub[j][0])\n",
      "        modis_dicts[i] = sds.GetMetadata()\n",
      "        modis[i] = np.array(sds.ReadAsArray())\n",
      "        makenan = True\n",
      "        bad_points = np.where(modis[i] == float(modis_dicts[i]['_FillValue']))\n",
      "        scale = float(modis_dicts[i]['scale_factor'])\n",
      "        offset = float(modis_dicts[i]['add_offset'])\n",
      "       # print 'MODIS array: %s, type: %s' % (i, modis[i].dtype)\n",
      "        if scale.is_integer():\n",
      "            scale = int(scale)\n",
      "            makenan = False\n",
      "        if scale != 1 and offset == 0:\n",
      "            modis[i] = modis[i]*scale+offset\n",
      "        if makenan:\n",
      "            modis[i][bad_points] = np.nan\n",
      "        progress(float(tuple(i[0] for i in modis_values).index(i))/len(modis_values)*100.)\n",
      "    endprogress()\n",
      "    print modis.keys()\n",
      "    del geosds, datsds,sds,lonsds,latsds,geosub,datsub\n",
      "    return modis,modis_dicts"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_ict(fname):\n",
      "    \"\"\"\n",
      "    Simple ict file loader\n",
      "    created specifically to load the files from the iwg1 on board the G1 during TCAP, may work with others...\n",
      "    \"\"\"\n",
      "    from datetime import datetime\n",
      "    import numpy as np\n",
      "    f = open(fname,'r')\n",
      "    lines = f.readlines()\n",
      "    first = lines[0]\n",
      "    num2skip = int(first.strip().split(',')[0])\n",
      "    header = lines[0:num2skip]\n",
      "    factor = map(float,header[10].strip().split(','))\n",
      "    f.close()\n",
      "    if any([i!=1 for i in factor]):\n",
      "        print('Some Scaling factors are not equal to one, Please check the factors:')\n",
      "        print factor\n",
      "    def mktime(txt):\n",
      "        return datetime.strptime(txt,'%Y-%m-%d %H:%M:%S')\n",
      "    def utctime(seconds_utc):\n",
      "        return float(seconds_utc)/3600.\n",
      "    conv = {\"Date_Time\":mktime, \"UTC\":utctime, \"Start_UTC\":utctime, \"TIME_UTC\":utctime}\n",
      "    data = np.genfromtxt(fname,names=True,delimiter=',',skip_header=num2skip-1,converters=conv)\n",
      "    print data.dtype.names\n",
      "    #scale the values by using the scale factors\n",
      "    for i,name in enumerate(data.dtype.names):\n",
      "        if i>0:\n",
      "            if factor[i-1]!=float(1):\n",
      "                data[name] = data[name]*factor[i-1]    \n",
      "    return data"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def modis_qa(qa_array):\n",
      "    \"\"\"\n",
      "    modis qa data parser.\n",
      "    input of qa numpy array\n",
      "    output structure of qa arrays\n",
      "    \"\"\"\n",
      "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mat2py_time(matlab_datenum):\n",
      "    \"convert a matlab datenum to a python datetime object. Works on numpy arrays of datenum\"\n",
      "    from datetime import datetime, timedelta\n",
      "    #matlab_datenum = 731965.04835648148\n",
      "    m2ptime = lambda tmat: datetime.fromordinal(int(tmat)) + timedelta(days=tmat%1) - timedelta(days = 366)\n",
      "    try:\n",
      "        python_datetime = m2ptim2(matlab_datenum)\n",
      "    except:\n",
      "        import numpy as np\n",
      "        python_datetime = np.array([m2ptime(matlab_datenum.flatten()[i]) for i in xrange(matlab_datenum.size)])\n",
      "    return python_datetime"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def toutc(pydatetime):\n",
      "    \"Convert python datetime to utc fractional hours\"\n",
      "    utc_fx = lambda x: float(x.hour)+float(x.minute)/60.0+float(x.second)/3600.0+float(x.microsecond)/360000000.0\n",
      "    try: \n",
      "        return utc_fx(pydatetime)\n",
      "    except:\n",
      "        import numpy as np\n",
      "        return np.array([utc_fx(pydatetime.flatten()[i])+(pydatetime.flatten()[i].day-pydatetime.flatten()[0].day)*24.0 \\\n",
      "                         for i in xrange(pydatetime.size)]) "
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_emas(datfile):\n",
      "    \"\"\"\n",
      "    Name:\n",
      "\n",
      "        load_emas\n",
      "    \n",
      "    Purpose:\n",
      "\n",
      "        to compile functions required to load emas files\n",
      "        from within another script.\n",
      "        Similar to load_modis\n",
      "    \n",
      "    Calling Sequence:\n",
      "\n",
      "        emas,emas_dict = load_emas(datfile) \n",
      "    \n",
      "    Input: \n",
      "  \n",
      "        datfile name (hdf files)\n",
      "    \n",
      "    Output:\n",
      "\n",
      "        emas dictionary with tau, ref, etau, eref, phase, qa\n",
      "        emas_dicts : metadate for each of the variables\n",
      "    \n",
      "    Keywords: \n",
      "\n",
      "        none\n",
      "    \n",
      "    Dependencies:\n",
      "\n",
      "        gdal\n",
      "        numpy\n",
      "        gc: for clearing the garbage\n",
      "    \n",
      "    Required files:\n",
      "   \n",
      "        dat files\n",
      "    \n",
      "    Example:\n",
      "\n",
      "        ...\n",
      "        \n",
      "    Modification History:\n",
      "    \n",
      "        Written (v1.0): Samuel LeBlanc, 2014-12-08, NASA Ames\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from osgeo import gdal\n",
      "    from Sp_parameters import startprogress, progress, endprogress\n",
      "    emas_values = (#('cloud_top',57),\n",
      "                    ('phase',53),\n",
      "          #          ('cloud_top_temp',58),\n",
      "                    ('ref',66),\n",
      "                    ('tau',72),\n",
      "           #         ('cwp',82),\n",
      "                    ('eref',90),\n",
      "                    ('etau',93),\n",
      "            #        ('ecwp',96),\n",
      "                    ('multi_layer',105),\n",
      "                    ('qa',123),\n",
      "             #       ('cloud_mask',110)\n",
      "                    )\n",
      "    datsds = gdal.Open(datfile)\n",
      "    datsub = datsds.GetSubDatasets()\n",
      "    print 'Outputting the Data subdatasets:'\n",
      "    for i in range(len(datsub)):\n",
      "        if any(i in val for val in emas_values):\n",
      "            print '\\x1b[1;36m%i: %s\\x1b[0m' %(i,datsub[i][1])\n",
      "        else:\n",
      "            print str(i)+': '+datsub[i][1]\n",
      "    emas = dict()\n",
      "    meta = datsds.GetMetadata() \n",
      "    import gc; gc.collect()\n",
      "    emas_dicts = dict()\n",
      "    startprogress('Running through modis values')\n",
      "    for i,j in emas_values:\n",
      "        sds = gdal.Open(datsub[j][0])\n",
      "        emas_dicts[i] = sds.GetMetadata()\n",
      "        emas[i] = np.array(sds.ReadAsArray())\n",
      "        makenan = True\n",
      "        bad_points = np.where(emas[i] == float(emas_dicts[i]['_FillValue']))\n",
      "        try:\n",
      "            scale = float(emas_dicts[i]['scale_factor'])\n",
      "            offset = float(emas_dicts[i]['add_offset'])\n",
      "            # print 'MODIS array: %s, type: %s' % (i, modis[i].dtype)\n",
      "            if scale.is_integer():\n",
      "               scale = int(scale)\n",
      "               makenan = False\n",
      "            if scale != 1 and offset == 0:\n",
      "               emas[i] = emas[i]*scale+offset\n",
      "        except:\n",
      "            if issubclass(emas[i].dtype.type, np.integer):\n",
      "                makenan = False\n",
      "        if makenan:\n",
      "            emas[i][bad_points] = np.nan\n",
      "        progress(float(tuple(i[0] for i in emas_values).index(i))/len(emas_values)*100.)\n",
      "    endprogress()\n",
      "    print emas.keys()\n",
      "    del datsds,sds,datsub\n",
      "    return emas,emas_dicts"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_hdf(datfile,values=None):\n",
      "    \"\"\"\n",
      "    Name:\n",
      "\n",
      "        load_hdf\n",
      "    \n",
      "    Purpose:\n",
      "\n",
      "        to compile functions required to load emas files\n",
      "        from within another script.\n",
      "        Similar to load_modis\n",
      "    \n",
      "    Calling Sequence:\n",
      "\n",
      "        hdf_dat,hdf_dict = load_hdf(datfile,Values=None) \n",
      "    \n",
      "    Input: \n",
      "  \n",
      "        datfile name (hdf files)\n",
      "    \n",
      "    Output:\n",
      "\n",
      "        hdf_dat dictionary with the names of values saved, with associated dictionary values\n",
      "        hdf_dicts : metadate for each of the variables\n",
      "    \n",
      "    Keywords: \n",
      "\n",
      "        values: if ommitted, only outputs the names of the variables in file\n",
      "                needs to be a tuple of 2 element tuples (first element name of variable, second number of record)\n",
      "                example: modis_values=(('cloud_top',57),('phase',53),('cloud_top_temp',58),('ref',66),('tau',72))\n",
      "    \n",
      "    Dependencies:\n",
      "\n",
      "        gdal\n",
      "        numpy\n",
      "        gc: for clearing the garbage\n",
      "        Sp_parameters for progress issuer\n",
      "    \n",
      "    Required files:\n",
      "   \n",
      "        dat files\n",
      "    \n",
      "    Example:\n",
      "\n",
      "        ...\n",
      "        \n",
      "    Modification History:\n",
      "    \n",
      "        Written (v1.0): Samuel LeBlanc, 2014-12-10, NASA Ames\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from osgeo import gdal\n",
      "    from Sp_parameters import startprogress, progress, endprogress\n",
      "    \n",
      "    datsds = gdal.Open(datfile)\n",
      "    datsub = datsds.GetSubDatasets()\n",
      "    print 'Outputting the Data subdatasets:'\n",
      "    for i in range(len(datsub)):\n",
      "        if values:\n",
      "            if any(i in val for val in values):\n",
      "                print '\\x1b[1;36m%i: %s\\x1b[0m' %(i,datsub[i][1])\n",
      "            else:\n",
      "                print str(i)+': '+datsub[i][1]\n",
      "        else:\n",
      "            print str(i)+': '+datsub[i][1]\n",
      "    if not values:\n",
      "        print 'Done going through file... Please supply pairs of name and index for reading file'\n",
      "        print \" in format values = (('name1',index1),('name2',index2),('name3',index3),...)\"\n",
      "        print \" where namei is the nameof the returned variable, and indexi is the index of the variable (from above)\"\n",
      "        return None, None\n",
      "    hdf = dict()\n",
      "    meta = datsds.GetMetadata() \n",
      "    import gc; gc.collect()\n",
      "    hdf_dicts = dict()\n",
      "    startprogress('Running through modis values')\n",
      "    for i,j in values:\n",
      "        sds = gdal.Open(datsub[j][0])\n",
      "        hdf_dicts[i] = sds.GetMetadata()\n",
      "        hdf[i] = np.array(sds.ReadAsArray())\n",
      "        if not hdf[i].any():\n",
      "            import pdb; pdb.set_trace()\n",
      "        try:\n",
      "            bad_points = np.where(hdf[i] == float(hdf_dicts[i]['_FillValue']))\n",
      "            makenan = True\n",
      "        except KeyError:\n",
      "            makenan = False\n",
      "        try:\n",
      "            scale = float(hdf_dicts[i]['scale_factor'])\n",
      "            offset = float(hdf_dicts[i]['add_offset'])\n",
      "            # print 'MODIS array: %s, type: %s' % (i, modis[i].dtype)\n",
      "            if scale.is_integer():\n",
      "               scale = int(scale)\n",
      "               makenan = False\n",
      "            if scale != 1 and offset == 0:\n",
      "               hdf[i] = hdf[i]*scale+offset\n",
      "        except:\n",
      "            if issubclass(hdf[i].dtype.type, np.integer):\n",
      "                makenan = False\n",
      "        if makenan:\n",
      "            hdf[i][bad_points] = np.nan\n",
      "        progress(float(tuple(i[0] for i in values).index(i))/len(values)*100.)\n",
      "    endprogress()\n",
      "    print hdf.keys()\n",
      "    del datsds,sds,datsub\n",
      "    return hdf,hdf_dicts"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def spherical_dist(pos1, pos2, r=3958.75):\n",
      "    \"Calculate the distance, in km, from one point to another (can use arrays)\"\n",
      "    import numpy as np\n",
      "    pos1 = pos1 * np.pi / 180\n",
      "    pos2 = pos2 * np.pi / 180\n",
      "    cos_lat1 = np.cos(pos1[..., 0])\n",
      "    cos_lat2 = np.cos(pos2[..., 0])\n",
      "    cos_lat_d = np.cos(pos1[..., 0] - pos2[..., 0])\n",
      "    cos_lon_d = np.cos(pos1[..., 1] - pos2[..., 1])\n",
      "    return r * np.arccos(cos_lat_d - cos_lat1 * cos_lat2 * (1 - cos_lon_d))"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def map_ind(mod_lon,mod_lat,meas_lon,meas_lat,meas_good=None):\n",
      "    \"\"\" Run to get indices in the measurement space of all the closest mod points. Assuming earth geometry.\"\"\"\n",
      "    from load_modis import spherical_dist\n",
      "    from Sp_parameters import startprogress, progress, endprogress\n",
      "    import numpy as np\n",
      "    if not any(meas_good):\n",
      "        meas_good = np.where(meas_lon)\n",
      "    imodis = np.logical_and(np.logical_and(mod_lon>min(meas_lon[meas_good])-0.02 , mod_lon<max(meas_lon[meas_good])+0.02),\n",
      "                            np.logical_and(mod_lat>min(meas_lat[meas_good])-0.02 , mod_lat<max(meas_lat[meas_good])+0.02))\n",
      "    wimodis = np.where(imodis)\n",
      "    N1 = mod_lon[imodis].size\n",
      "    modis_grid = np.hstack([mod_lon[imodis].reshape((N1,1)),mod_lat[imodis].reshape((N1,1))])\n",
      "    N2 = len(meas_good)\n",
      "    meas_grid = np.hstack([np.array(meas_lon[meas_good]).reshape((N2,1)),np.array(meas_lat[meas_good]).reshape((N2,1))])\n",
      "    meas_in = meas_grid.astype(int)\n",
      "    meas_ind = np.array([meas_good.ravel()*0,meas_good.ravel()*0])\n",
      "    startprogress('Running through flight track')\n",
      "    for i in xrange(meas_good.size):\n",
      "        d = spherical_dist(meas_grid[i],modis_grid)\n",
      "        meas_ind[0,i] = wimodis[0][np.argmin(d)]\n",
      "        meas_ind[1,i] = wimodis[1][np.argmin(d)]\n",
      "        progress(float(i)/len(meas_good)*100)\n",
      "    endprogress()\n",
      "    return meas_ind"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_cpl_layers(datfile,values=None):\n",
      "    \"\"\"\n",
      "    Name:\n",
      "\n",
      "        load_cpl_layers\n",
      "    \n",
      "    Purpose:\n",
      "\n",
      "        Function to load cpl files of layer properties 'layers_'\n",
      "        This funciton is called from another script\n",
      "    \n",
      "    Calling Sequence:\n",
      "\n",
      "        cpl_layers = load_cpl_layers(datfile) \n",
      "    \n",
      "    Input: \n",
      "  \n",
      "        datfile name (layers text files)\n",
      "    \n",
      "    Output:\n",
      "\n",
      "        cpl_layers: dictionary with associated properties such as time, A/C altitude, latitude, longitude, and roll\n",
      "                    number of layers, Ground height (GH) in meters above MSL, top and bottom altitude of each layer, and type of layer\n",
      "    \n",
      "    Keywords: \n",
      "\n",
      "        none\n",
      "    \n",
      "    Dependencies:\n",
      "\n",
      "        os\n",
      "        numpy\n",
      "        re : for regular experessions\n",
      "    \n",
      "    Required files:\n",
      "   \n",
      "        layers text files\n",
      "    \n",
      "    Example:\n",
      "\n",
      "        ...\n",
      "        \n",
      "    Modification History:\n",
      "    \n",
      "        Written (v1.0): Samuel LeBlanc, 2015-03-24, NASA Ames\n",
      "    \"\"\"\n",
      "    import os\n",
      "    if not(os.path.isfile(datfile)):\n",
      "        error('File not found!')\n",
      "    import numpy as np\n",
      "    import re\n",
      "\n",
      "    # set variables to read\n",
      "    num_lines = sum(1 for line in open(datfile))\n",
      "    head_lines = 14\n",
      "    d = np.empty(num_lines-head_lines,dtype=[('hh','i4'),\n",
      "                                             ('mm','i4'),\n",
      "                                             ('ss','i4'),\n",
      "                                             ('lat','f8'),\n",
      "                                             ('lon','f8'),\n",
      "                                             ('alt','f8'),\n",
      "                                             ('rol','f8'),\n",
      "                                             ('num','i4'),\n",
      "                                             ('gh','f8'),\n",
      "                                             ('top','f8',(10)),\n",
      "                                             ('bot','f8',(10)),\n",
      "                                             ('type','i4',(10)),\n",
      "                                             ('utc','f8')])\n",
      "    d[:] = np.NAN\n",
      "    header = ''\n",
      "    with open(datfile) as fp:\n",
      "        for iline, line in enumerate(fp):\n",
      "            if iline<head_lines:\n",
      "                header = header + line\n",
      "            else:\n",
      "                i = iline-head_lines\n",
      "                line = line.strip()\n",
      "                temp = filter(None, re.split(r\"[ :()]\",line))\n",
      "                d['hh'][i], d['mm'][i], d['ss'][i] = temp[0], temp[1], temp[2]\n",
      "                d['lat'][i], d['lon'][i], d['alt'][i] = temp[3], temp[4], temp[5]\n",
      "                d['rol'][i], d['num'][i], d['gh'][i] = temp[6], temp[7], temp[8]\n",
      "                for n in range(d['num'][i]):\n",
      "                    try:\n",
      "                        d['top'][i][n], d['bot'][i][n], d['type'][i][n] = temp[9+3*n], temp[9+3*n+1], temp[9+3*n+2]\n",
      "                    except:\n",
      "                        import pdb; pdb.set_trace()\n",
      "                d['utc'][i] = float(d['hh'][i])+float(d['mm'][i])/60.0+float(d['ss'][i])/3600.0\n",
      "                \n",
      "    return d"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing of the script:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == \"__main__\":"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    import os\n",
      "    import numpy as np\n",
      "    from osgeo import gdal"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    fp='C:\\\\Users\\\\sleblan2\\\\Research\\\\TCAP\\\\'"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    myd06_file = fp+'MODIS\\\\MYD06_L2.A2013050.1725.006.2014260074007.hdf'\n",
      "    myd03_file = fp+'MODIS\\\\MYD03.A2013050.1725.006.2013051163424.hdf'\n",
      "    print os.path.isfile(myd03_file) #check if it exists\n",
      "    print os.path.isfile(myd06_file)"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    myd_geo = gdal.Open(myd03_file)\n",
      "    myd_geo_sub = myd_geo.GetSubDatasets()\n",
      "    for i in range(len(myd_geo_sub)):\n",
      "        print str(i)+': '+myd_geo_sub[i][1]"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    latsds = gdal.Open(myd_geo_sub[12][0],gdal.GA_ReadOnly)\n",
      "    lonsds = gdal.Open(myd_geo_sub[13][0],gdal.GA_ReadOnly)\n",
      "    szasds = gdal.Open(myd_geo_sub[21][0],gdal.GA_ReadOnly)"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    print latsds.RasterCount # verify that only one raster exists\n",
      "    lat = latsds.ReadAsArray()\n",
      "    lon = lonsds.ReadAsArray()\n",
      "    sza = szasds.ReadAsArray()\n",
      "    print lon.shape"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now load the specific data files:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    myd_dat = gdal.Open(myd06_file)\n",
      "    myd_dat_sub = myd_dat.GetSubDatasets()\n",
      "    for i in range(len(myd_dat_sub)):\n",
      "        print str(i)+': '+myd_dat_sub[i][1]"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    print myd_dat_sub[118]\n",
      "    retfsds = gdal.Open(myd_dat_sub[118][0])"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    for key,value in myd_dat.GetMetadata_Dict().items():\n",
      "        print key,value"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the different modis values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    modis_values = (('cloud_top',57),\n",
      "                    ('phase',53),\n",
      "                    ('cloud_top_temp',58),\n",
      "                    ('ref',66),\n",
      "                    ('tau',72),\n",
      "                    ('cwp',82),\n",
      "                    ('eref',90),\n",
      "                    ('etau',93),\n",
      "                    ('ecwp',96),\n",
      "                    ('multi_layer',105),\n",
      "                    ('qa',123),\n",
      "                    ('cloud_mask',110)\n",
      "                    )"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing the metadata dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    gdal.Open(myd_dat_sub[53][0]).GetMetadata()"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    mm = dict()\n",
      "    mm['one'] = gdal.Open(myd_dat_sub[72][0]).GetMetadata()\n",
      "    mm['two'] = gdal.Open(myd_dat_sub[74][0]).GetMetadata()\n",
      "    mm['two']['_FillValue']"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    from Sp_parameters import startprogress, progress, endprogress\n",
      "    import gc; gc.collect()"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    tuple(i[0] for i in modis_values).index('etau')"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    modis = dict()\n",
      "    modis_dicts = dict()\n",
      "    startprogress('Running through modis values')\n",
      "    for i,j in modis_values:\n",
      "        sds = gdal.Open(myd_dat_sub[j][0])\n",
      "        modis_dicts[i] = sds.GetMetadata()\n",
      "        modis[i] = np.array(sds.ReadAsArray())*float(modis_dicts[i]['scale_factor'])+float(modis_dicts[i]['add_offset'])\n",
      "        modis[i][modis[i] == float(modis_dicts[i]['_FillValue'])] = np.nan\n",
      "        progress(float(tuple(i[0] for i in modis_values).index(i))/len(modis_values)*100.)\n",
      "    endprogress()"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    print modis.keys()\n",
      "    print modis_dicts.keys()"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}