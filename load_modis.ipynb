{
 "metadata": {
  "name": "",
  "signature": "sha256:bf09935df39c630440a120bcb42a79ad2f5c3e332499e60c02750893e54f73ad"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def __init__():\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_modis(geofile,datfile):\n",
      "    \"\"\"\n",
      "    Name:\n",
      "\n",
      "        load_modis\n",
      "    \n",
      "    Purpose:\n",
      "\n",
      "        to compile functions required to load Modis files\n",
      "        from within another script\n",
      "    \n",
      "    Calling Sequence:\n",
      "\n",
      "        modis,modis_dict = load_modis(geofile,datfile) \n",
      "    \n",
      "    Input: \n",
      "  \n",
      "        geofile name\n",
      "        datfile name (hdf files)\n",
      "    \n",
      "    Output:\n",
      "\n",
      "        modis dictionary with tau, ref, etau, eref, phase, qa\n",
      "        modis_dicts : metadate for each of the variables\n",
      "    \n",
      "    Keywords: \n",
      "\n",
      "        none\n",
      "    \n",
      "    Dependencies:\n",
      "\n",
      "        gdal\n",
      "        numpy\n",
      "        gc: for clearing the garbage\n",
      "    \n",
      "    Required files:\n",
      "   \n",
      "        geo and dat files\n",
      "    \n",
      "    Example:\n",
      "\n",
      "        ...\n",
      "        \n",
      "    Modification History:\n",
      "    \n",
      "        Written (v1.0): Samuel LeBlanc, 2014-12-08, NASA Ames\n",
      "        \n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from osgeo import gdal\n",
      "    from Sp_parameters import startprogress, progress, endprogress\n",
      "    modis_values = (#('cloud_top',57),\n",
      "                    ('phase',53),\n",
      "          #          ('cloud_top_temp',58),\n",
      "                    ('ref',66),\n",
      "                    ('tau',72),\n",
      "           #         ('cwp',82),\n",
      "                    ('eref',90),\n",
      "                    ('etau',93),\n",
      "            #        ('ecwp',96),\n",
      "                    ('multi_layer',105),\n",
      "                    ('qa',123),\n",
      "             #       ('cloud_mask',110)\n",
      "                    )\n",
      "    geosds = gdal.Open(geofile)\n",
      "    datsds = gdal.Open(datfile)\n",
      "    geosub = geosds.GetSubDatasets()\n",
      "    datsub = datsds.GetSubDatasets()\n",
      "    print 'Outputting the Geo subdatasets:'\n",
      "    for i in range(len(geosub)):\n",
      "        print str(i)+': '+geosub[i][1]\n",
      "    print 'Outputting the Data subdatasets:'\n",
      "    for i in range(len(datsub)):\n",
      "        if any(i in val for val in modis_values):\n",
      "            print '\\x1b[1;36m%i: %s\\x1b[0m' %(i,datsub[i][1])\n",
      "        else:\n",
      "            print str(i)+': '+datsub[i][1]\n",
      "    latsds = gdal.Open(geosub[12][0],gdal.GA_ReadOnly)\n",
      "    lonsds = gdal.Open(geosub[13][0],gdal.GA_ReadOnly)\n",
      "    szasds = gdal.Open(geosub[21][0],gdal.GA_ReadOnly)\n",
      "    modis = dict()\n",
      "    modis['lat'] = latsds.ReadAsArray()\n",
      "    modis['lon'] = lonsds.ReadAsArray()\n",
      "    modis['sza'] = szasds.ReadAsArray()\n",
      "    print modis['lon'].shape\n",
      "    meta = datsds.GetMetadata() \n",
      "    import gc; gc.collect()\n",
      "    modis_dicts = dict()\n",
      "    startprogress('Running through modis values')\n",
      "    for i,j in modis_values:\n",
      "        sds = gdal.Open(datsub[j][0])\n",
      "        modis_dicts[i] = sds.GetMetadata()\n",
      "        modis[i] = np.array(sds.ReadAsArray())\n",
      "        makenan = True\n",
      "        bad_points = np.where(modis[i] == float(modis_dicts[i]['_FillValue']))\n",
      "        scale = float(modis_dicts[i]['scale_factor'])\n",
      "        offset = float(modis_dicts[i]['add_offset'])\n",
      "       # print 'MODIS array: %s, type: %s' % (i, modis[i].dtype)\n",
      "        if scale.is_integer():\n",
      "            scale = int(scale)\n",
      "            makenan = False\n",
      "        if scale != 1 and offset == 0:\n",
      "            modis[i] = modis[i]*scale+offset\n",
      "        if makenan:\n",
      "            modis[i][bad_points] = np.nan\n",
      "        progress(float(tuple(i[0] for i in modis_values).index(i))/len(modis_values)*100.)\n",
      "    endprogress()\n",
      "    print modis.keys()\n",
      "    del geosds, datsds,sds,lonsds,latsds,geosub,datsub\n",
      "    return modis,modis_dicts"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_ict(fname):\n",
      "    \"\"\"\n",
      "    Simple ict file loader\n",
      "    created specifically to load the files from the iwg1 on oard the G1 during TCAP, may work with others...\n",
      "    \"\"\"\n",
      "    from datetime import datetime\n",
      "    import numpy as np\n",
      "    f = open(fname,'r')\n",
      "    first = f.readline()\n",
      "    num2skip = int(first.strip().split(',')[0])\n",
      "    f.close()\n",
      "    def mktime(txt):\n",
      "        return datetime.strptime(txt,'%Y-%m-%d %H:%M:%S')\n",
      "    def utctime(seconds_utc):\n",
      "        return float(seconds_utc)/3600.\n",
      "    conv = {\"Date_Time\":mktime, \"UTC\":utctime, \"Start_UTC\":utctime}\n",
      "    data = np.genfromtxt(fname,names=True,delimiter=',',skip_header=num2skip-1,dtype=None,converters=conv)\n",
      "    print data.dtype.names\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def modis_qa(qa_array):\n",
      "    \"\"\"\n",
      "    modis qa data parser.\n",
      "    input of qa numpy array\n",
      "    output structure of qa arrays\n",
      "    \"\"\"\n",
      "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mat2py_time(matlab_datenum):\n",
      "    \"convert a matlab datenum to a python datetime object. Works on numpy arrays of datenum\"\n",
      "    from datetime import datetime, timedelta\n",
      "    #matlab_datenum = 731965.04835648148\n",
      "    m2ptime = lambda tmat: datetime.fromordinal(int(tmat)) + timedelta(days=tmat%1) - timedelta(days = 366)\n",
      "    try:\n",
      "        python_datetime = m2ptim2(matlab_datenum)\n",
      "    except:\n",
      "        import numpy as np\n",
      "        python_datetime = np.array([m2ptime(matlab_datenum.flatten()[i]) for i in xrange(matlab_datenum.size)])\n",
      "    return python_datetime"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def toutc(pydatetime):\n",
      "    \"Convert python datetime to utc fractional hours\"\n",
      "    utc_fx = lambda x: float(x.hour)+float(x.minute)/60.0+float(x.second)/3600.0+float(x.microsecond)/360000000.0\n",
      "    try: \n",
      "        return utc_fx(pydatetime)\n",
      "    except:\n",
      "        import numpy as np\n",
      "        return np.array([utc_fx(pydatetime.flatten()[i])+(pydatetime.flatten()[i].day-pydatetime.flatten()[0].day)*24.0 \\\n",
      "                         for i in xrange(pydatetime.size)]) "
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_emas(datfile):\n",
      "    \"\"\"\n",
      "    Name:\n",
      "\n",
      "        load_emas\n",
      "    \n",
      "    Purpose:\n",
      "\n",
      "        to compile functions required to load emas files\n",
      "        from within another script.\n",
      "        Similar to load_modis\n",
      "    \n",
      "    Calling Sequence:\n",
      "\n",
      "        emas,emas_dict = load_emas(datfile) \n",
      "    \n",
      "    Input: \n",
      "  \n",
      "        datfile name (hdf files)\n",
      "    \n",
      "    Output:\n",
      "\n",
      "        emas dictionary with tau, ref, etau, eref, phase, qa\n",
      "        emas_dicts : metadate for each of the variables\n",
      "    \n",
      "    Keywords: \n",
      "\n",
      "        none\n",
      "    \n",
      "    Dependencies:\n",
      "\n",
      "        gdal\n",
      "        numpy\n",
      "        gc: for clearing the garbage\n",
      "    \n",
      "    Required files:\n",
      "   \n",
      "        dat files\n",
      "    \n",
      "    Example:\n",
      "\n",
      "        ...\n",
      "        \n",
      "    Modification History:\n",
      "    \n",
      "        Written (v1.0): Samuel LeBlanc, 2014-12-08, NASA Ames\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from osgeo import gdal\n",
      "    from Sp_parameters import startprogress, progress, endprogress\n",
      "    emas_values = (#('cloud_top',57),\n",
      "                    ('phase',53),\n",
      "          #          ('cloud_top_temp',58),\n",
      "                    ('ref',66),\n",
      "                    ('tau',72),\n",
      "           #         ('cwp',82),\n",
      "                    ('eref',90),\n",
      "                    ('etau',93),\n",
      "            #        ('ecwp',96),\n",
      "                    ('multi_layer',105),\n",
      "                    ('qa',123),\n",
      "             #       ('cloud_mask',110)\n",
      "                    )\n",
      "    datsds = gdal.Open(datfile)\n",
      "    datsub = datsds.GetSubDatasets()\n",
      "    print 'Outputting the Data subdatasets:'\n",
      "    for i in range(len(datsub)):\n",
      "        if any(i in val for val in emas_values):\n",
      "            print '\\x1b[1;36m%i: %s\\x1b[0m' %(i,datsub[i][1])\n",
      "        else:\n",
      "            print str(i)+': '+datsub[i][1]\n",
      "    emas = dict()\n",
      "    meta = datsds.GetMetadata() \n",
      "    import gc; gc.collect()\n",
      "    emas_dicts = dict()\n",
      "    startprogress('Running through modis values')\n",
      "    for i,j in emas_values:\n",
      "        sds = gdal.Open(datsub[j][0])\n",
      "        emas_dicts[i] = sds.GetMetadata()\n",
      "        emas[i] = np.array(sds.ReadAsArray())\n",
      "        makenan = True\n",
      "        bad_points = np.where(emas[i] == float(emas_dicts[i]['_FillValue']))\n",
      "        scale = float(emas_dicts[i]['scale_factor'])\n",
      "        offset = float(emas_dicts[i]['add_offset'])\n",
      "       # print 'MODIS array: %s, type: %s' % (i, modis[i].dtype)\n",
      "        if scale.is_integer():\n",
      "            scale = int(scale)\n",
      "            makenan = False\n",
      "        if scale != 1 and offset == 0:\n",
      "            emas[i] = emas[i]*scale+offset\n",
      "        if makenan:\n",
      "            emas[i][bad_points] = np.nan\n",
      "        progress(float(tuple(i[0] for i in modis_values).index(i))/len(modis_values)*100.)\n",
      "    endprogress()\n",
      "    print emas.keys()\n",
      "    del datsds,sds,datsub\n",
      "    return emas,emas_dicts"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing of the script:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == \"__main__\":"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    import os\n",
      "    import numpy as np\n",
      "    from osgeo import gdal"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    fp='C:\\\\Users\\\\sleblan2\\\\Research\\\\TCAP\\\\'"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    myd06_file = fp+'MODIS\\\\MYD06_L2.A2013050.1725.006.2014260074007.hdf'\n",
      "    myd03_file = fp+'MODIS\\\\MYD03.A2013050.1725.006.2013051163424.hdf'\n",
      "    print os.path.isfile(myd03_file) #check if it exists\n",
      "    print os.path.isfile(myd06_file)"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    myd_geo = gdal.Open(myd03_file)\n",
      "    myd_geo_sub = myd_geo.GetSubDatasets()\n",
      "    for i in range(len(myd_geo_sub)):\n",
      "        print str(i)+': '+myd_geo_sub[i][1]"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    latsds = gdal.Open(myd_geo_sub[12][0],gdal.GA_ReadOnly)\n",
      "    lonsds = gdal.Open(myd_geo_sub[13][0],gdal.GA_ReadOnly)\n",
      "    szasds = gdal.Open(myd_geo_sub[21][0],gdal.GA_ReadOnly)"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    print latsds.RasterCount # verify that only one raster exists\n",
      "    lat = latsds.ReadAsArray()\n",
      "    lon = lonsds.ReadAsArray()\n",
      "    sza = szasds.ReadAsArray()\n",
      "    print lon.shape"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now load the specific data files:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    myd_dat = gdal.Open(myd06_file)\n",
      "    myd_dat_sub = myd_dat.GetSubDatasets()\n",
      "    for i in range(len(myd_dat_sub)):\n",
      "        print str(i)+': '+myd_dat_sub[i][1]"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    print myd_dat_sub[118]\n",
      "    retfsds = gdal.Open(myd_dat_sub[118][0])"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    for key,value in myd_dat.GetMetadata_Dict().items():\n",
      "        print key,value"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the different modis values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    modis_values = (('cloud_top',57),\n",
      "                    ('phase',53),\n",
      "                    ('cloud_top_temp',58),\n",
      "                    ('ref',66),\n",
      "                    ('tau',72),\n",
      "                    ('cwp',82),\n",
      "                    ('eref',90),\n",
      "                    ('etau',93),\n",
      "                    ('ecwp',96),\n",
      "                    ('multi_layer',105),\n",
      "                    ('qa',123),\n",
      "                    ('cloud_mask',110)\n",
      "                    )"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing the metadata dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    gdal.Open(myd_dat_sub[53][0]).GetMetadata()"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    mm = dict()\n",
      "    mm['one'] = gdal.Open(myd_dat_sub[72][0]).GetMetadata()\n",
      "    mm['two'] = gdal.Open(myd_dat_sub[74][0]).GetMetadata()\n",
      "    mm['two']['_FillValue']"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    from Sp_parameters import startprogress, progress, endprogress\n",
      "    import gc; gc.collect()"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    tuple(i[0] for i in modis_values).index('etau')"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    modis = dict()\n",
      "    modis_dicts = dict()\n",
      "    startprogress('Running through modis values')\n",
      "    for i,j in modis_values:\n",
      "        sds = gdal.Open(myd_dat_sub[j][0])\n",
      "        modis_dicts[i] = sds.GetMetadata()\n",
      "        modis[i] = np.array(sds.ReadAsArray())*float(modis_dicts[i]['scale_factor'])+float(modis_dicts[i]['add_offset'])\n",
      "        modis[i][modis[i] == float(modis_dicts[i]['_FillValue'])] = np.nan\n",
      "        progress(float(tuple(i[0] for i in modis_values).index(i))/len(modis_values)*100.)\n",
      "    endprogress()"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    print modis.keys()\n",
      "    print modis_dicts.keys()"
     ],
     "language": "python",
     "metadata": {
      "run_control": {
       "breakpoint": false,
       "read_only": false
      }
     },
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}